{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain adaptation (5 pts total)\n",
    "\n",
    "In this seminar you will adapt a pre-trained machine translation model for the hotel review translation task you solved a few weeks ago. \n",
    "\n",
    "This time it comes with a few complications:\n",
    "* Harder task: __en -> ru__ instead of __ru -> en__\n",
    "* You are given a model pre-trained on WMT. Visit [statmt.org](http://statmt.org/) for more details.\n",
    "* The baseline model already includes attention and some hacks\n",
    "\n",
    "With luck and skills on your side, you will adapt it to improve hotel translation quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install subword-nmt &> log\n",
    "!wget https://github.com/yandexdataschool/nlp_course/raw/master/week09_da/data.tar.gz\n",
    "!wget https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week09_da/utils.py\n",
    "!tar -xvzf data.tar.gz\n",
    "!mv data/* .\n",
    "!wget https://www.dropbox.com/s/xm73pjug7eq1rff/model-pretrained.npz?dl=1 -O model-pretrained.npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "We provide you with a pre-trained model that uses Byte Pair Encodings [(bpe)](https://github.com/rsennrich/subword-nmt) to segment rare words into sub-word units. \n",
    "\n",
    "It is important that we fine-tune our model using the same set of BPE rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.apply_bpe import BPE\n",
    "tokenizer = WordPunctTokenizer()\n",
    "def tokenize(x):\n",
    "    return ' '.join(tokenizer.tokenize(x.lower()))\n",
    "\n",
    "bpe = {}\n",
    "for lang in ['en', 'ru']:\n",
    "    bpe[lang] = BPE(open('./bpe_rules.' + lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bpe['ru'].process_line(tokenize(\"Скажи: какого цвета глаза у ветра?\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inp_raw = list(open('./train.domain.en'))\n",
    "data_out_raw = list(open('./train.domain.ru'))\n",
    "\n",
    "print(data_inp_raw[0])\n",
    "print(data_out_raw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lines into space-separated tokenized bpe units\n",
    "<YOUR CODE>\n",
    "data_inp = <...>\n",
    "data_out = <...>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data_inp[0] == 'cor@@ del@@ ia hotel is situated in t@@ bil@@ isi , a 3 - minute walk away from saint tr@@ inity church .'\n",
    "assert data_out[500] == 'некоторые номера также располага@@ ют бал@@ ко@@ ном или тер@@ ра@@ со@@ й .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_inp, data_out = map(np.array, [data_inp, data_out])\n",
    "train_inp, dev_inp, train_out, dev_out = train_test_split(data_inp, data_out, test_size=3000,\n",
    "                                                          random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "For this assignment, you are given a pre-trained neural machine translation model:\n",
    "* bidirectional LSTM encoder\n",
    "* single LSTM decoder with additive attention\n",
    "\n",
    "It was trained till convergence on the general dataset of news, websites and literature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "inp_voc = utils.Vocab(open('tokens.en').read().split('\\n'))\n",
    "out_voc = utils.Vocab(open('tokens.ru').read().split('\\n'))\n",
    "\n",
    "model = utils.Model('mod', inp_voc, out_voc)\n",
    "utils.load(tf.trainable_variables(), 'model-pretrained.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = 'i am the monument to all your sins'\n",
    "src = bpe['en'].process_line(tokenize(src))\n",
    "trans, _ = model.translate_lines([src])\n",
    "print(trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate baseline quality\n",
    "\n",
    "As before, we shall estimate our model's quality using [BLEU](https://en.wikipedia.org/wiki/BLEU) metric.\n",
    "\n",
    "This metric simply computes which fraction of predicted n-grams is actually present in the reference translation. It does so for n=1,2,3 and 4 and computes the geometric average with penalty if translation is shorter than reference.\n",
    "\n",
    "One important thing about BLEU is that it is usually computed on a __corpora level__:\n",
    "* first you count precisions over the entire test set\n",
    "* then you do the geometric averaging and apply penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "def bleu(references, translations):\n",
    "    \"\"\" Estimates corpora-level BLEU score of predicted translations given references \"\"\"\n",
    "    return corpus_bleu([[ref.split()] for ref in references], \n",
    "                       [trans.split() for trans in translations]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu(['a cat sat on a mat', 'i love bees'], \n",
    "     ['a cat sat on a cat', 'i hate people'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 1 (1 point):__ evaluate baseline BLEU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, inp_lines, out_lines):\n",
    "    \"\"\"\n",
    "    Estimates model's corpora level bleu\n",
    "    :param inp_lines: a list of BPE strings in source language\n",
    "    :param out_lines: a list of BPE strings in target language\n",
    "    :returns: model's BLEU (float scalar)\n",
    "    \n",
    "    Important:\n",
    "    * Make sure to de-BPEize both translations and references. You can do that with str.replace\n",
    "    * Use model.translate_lines with default max_len\n",
    "    * If you're low on RAM, split data in several batches and translate sequentially\n",
    "    \"\"\"\n",
    "    \n",
    "    <YOUR CODE>\n",
    "    return <...>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, dev_inp[:500], dev_out[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive training (1.5 points)\n",
    "\n",
    "The simplest thing you can do in supervised domain adaptation is to simply fine-tune your model on the target domain data.\n",
    "\n",
    "Here's a reminder of what training objective looks like:\n",
    "$$ L = {\\frac1{|D|}} \\sum_{X, Y \\in D} \\sum_{y_t \\in Y} - \\log p(y_t \\mid y_1, \\dots, y_{t-1}, X, \\theta) $$\n",
    "\n",
    "where $|D|$ is the __total length of all sequences__.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import select_values_over_last_axis\n",
    "\n",
    "def compute_loss(model, inp, out, **flags):\n",
    "    \"\"\"\n",
    "    Compute loss (float32 scalar) as in the formula above\n",
    "    :param inp: input tokens matrix, int32[batch, time]\n",
    "    :param out: reference tokens matrix, int32[batch, time]\n",
    "    \"\"\"\n",
    "    first_state = model.encode(inp, **flags)\n",
    "    batch_size = tf.shape(inp)[0]\n",
    "    bos = tf.fill([batch_size], model.out_voc.bos_ix)\n",
    "    first_logits = tf.log(tf.one_hot(bos, len(model.out_voc)) + 1e-30)\n",
    "    \n",
    "    def step(blob, y_prev):\n",
    "        h_prev = blob[:-1]\n",
    "        h_new, logits = model.decode(h_prev, y_prev, **flags)\n",
    "        return list(h_new) + [logits]\n",
    "\n",
    "    *states_seq, logits_seq = tf.scan(step,\n",
    "                                       initializer=list(first_state) + [first_logits],\n",
    "                                       elems=tf.transpose(out))\n",
    "\n",
    "    # gather state and logits, each of shape [time, batch, ...]\n",
    "    logits_seq = tf.concat((first_logits[None], logits_seq),axis=0)\n",
    "    #convert from [time, batch,...] to [batch, time, ...]\n",
    "    logits_seq = tf.transpose(logits_seq, [1, 0, 2])\n",
    "    \n",
    "    logprobs_seq = tf.nn.log_softmax(logits_seq, dim=-1)\n",
    "    \n",
    "    logp_out = select_values_over_last_axis(logprobs_seq, out)\n",
    "    mask = utils.infer_mask(out, out_voc.eos_ix)\n",
    "    return -tf.reduce_sum(logp_out * mask) / tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tf.placeholder('int32', [None, None])\n",
    "out = tf.placeholder('int32', [None, None])\n",
    "\n",
    "loss = compute_loss(model, inp, out)\n",
    "\n",
    "train_step = tf.train.AdamOptimizer().minimize(loss)\n",
    "utils.initialize_uninitialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "batch_size = 32\n",
    "metrics = {'train_loss': [], 'dev_bleu': [] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in trange(10000):\n",
    "    step = len(metrics['train_loss']) + 1\n",
    "    batch_ix = np.random.randint(len(train_inp), size=32)\n",
    "    feed_dict = {\n",
    "        inp: inp_voc.to_matrix(train_inp[batch_ix]),\n",
    "        out: out_voc.to_matrix(train_out[batch_ix]),\n",
    "    }\n",
    "    \n",
    "    loss_t, _ = sess.run([loss, train_step], feed_dict)\n",
    "    metrics['train_loss'].append((step, loss_t))\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        metrics['dev_bleu'].append((step, evaluate(model, dev_inp, dev_out)))\n",
    "        \n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(12,4))\n",
    "        for i, (name, history) in enumerate(sorted(metrics.items())):\n",
    "            plt.subplot(1, len(metrics), i + 1)\n",
    "            plt.title(name)\n",
    "            plt.plot(*zip(*history))\n",
    "            plt.grid()\n",
    "        plt.show()\n",
    "        print(\"Mean loss=%.3f\" % np.mean(metrics['train_loss'][-10:], axis=0)[1], flush=True)\n",
    "        \n",
    "# Note: it's okay if bleu oscillates up and down as long as it gets better on average over long term (e.g. 5k batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.mean(metrics['dev_bleu'][-10:], axis=0)[1] > 30, \"We kind of need a higher bleu BLEU from you. Kind of right now.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print translations of some random dev lines\n",
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain adaptation with KL penalty (2.5 pts)\n",
    "\n",
    "The problem with fine-tuning is that model can stray too far from the original parameters and forget useful information. One way to mitigate this problem is to use KL penalty:\n",
    "\n",
    "$$ Loss = (1 - \\lambda) \\cdot L_{xent} + \\lambda \\cdot {1 \\over N} \\underset {x, y_t} \\sum KL(P_{teacher}(y_t|x, y_0, ..., y_{t-1}) || P_{student}(y_t|x, y_0, ..., y_{t-1}))$$\n",
    "__Note:__ make sure you only optimize student weights (i.e. don't train teacher network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "model = utils.Model('mod', inp_voc, out_voc)\n",
    "utils.load(tf.trainable_variables(), 'model-pretrained.npz')\n",
    "\n",
    "teacher = utils.Model('teacher', inp_voc, out_voc)\n",
    "\n",
    "teacher_ckpt = np.load('model-pretrained.npz')\n",
    "teacher_ckpt = { name.replace('mod/', 'teacher/'): teacher_ckpt[name] for name in teacher_ckpt}\n",
    "np.savez('teacher.npz', **teacher_ckpt)\n",
    "utils.load(tf.trainable_variables(), 'teacher.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_loss_with_kl(model, teacher, inp, out, lambda_coeff=0.25, **flags):\n",
    "    \"\"\"\n",
    "    Compute loss (float32 scalar) as in the formula above\n",
    "    :param inp: input tokens matrix, int32[batch, time]\n",
    "    :param out: reference tokens matrix, int32[batch, time]\n",
    "    :param lambda_coeff: lambda from the formula above.\n",
    "    \n",
    "    use lambda_coeff from outer scope\n",
    "    \"\"\"\n",
    "    \n",
    "    loss = <YOUR CODE>\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do it yourself: create training step operations and \n",
    "# feel free to copy the code from simple fine-tuning\n",
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<YOUR CODE: training loop>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do it yourself: estimate the final quality\n",
    "# feel free to reuse the code from simple fine-tuning\n",
    "<YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus tasks:\n",
    "Both tasks start at 3 points for basic solution and a ton more if you do something as awesome as the stuff from the lecture.\n",
    "\n",
    "1. __Domain adaptation with unlabeled data:__\n",
    " * In machine translation, it's relatively easy to obtain unparallel data. For the hotels task, there's almost 10x as large a corpora available if you \n",
    " * Download the full data [here](https://yadi.sk/d/zrYuTKQ63S33m3)\n",
    " * The dataset was originally provided by [Tilde](https://www.tilde.com/). Huge thanks to them! :)\n",
    " * The goal is simple: improve the model using the extra data. You can use proxy labels, pre-train as language model or do literally anything else.\n",
    " * Using extra out-of-domain data, whether parallel or not, is also encouraged. Here's [statmt](http://www.statmt.org/) with parallel corpora section at the bottom.\n",
    "\n",
    " \n",
    "2. __Beam search:__\n",
    " * While it's not related to domain adaption, beam search is a good general way to improve model inference.\n",
    " * The key idea of beam search if to consider not top-1 but top-K hypotheses at each step\n",
    " * In the example below, k=4\n",
    " * Whenever a hypothesis in top-K is finished (with a `_EOS_`), record it and remember it's score.\n",
    " * Iterate until all hypotheses are already worse than the best finished hypo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/beam_search.html 2> log\n",
    "from IPython.display import HTML\n",
    "# source: parlament does not support the amendment freeing tymoshenko\n",
    "HTML('./beam_search.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
