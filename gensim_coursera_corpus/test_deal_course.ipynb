{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coursera_corpus', encoding='utf-8') as f:\n",
    "    content = f.readlines()\n",
    "courses = [line.strip() for line in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_name = [course.split('\\t')[0] for course in courses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Fulton',\n",
       " 'County',\n",
       " 'Grand',\n",
       " 'Jury',\n",
       " 'said',\n",
       " 'Friday',\n",
       " 'an',\n",
       " 'investigation',\n",
       " 'of']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('Fulton', 'NP-TL'),\n",
       " ('County', 'NN-TL'),\n",
       " ('Grand', 'JJ-TL'),\n",
       " ('Jury', 'NN-TL'),\n",
       " ('said', 'VBD'),\n",
       " ('Friday', 'NR'),\n",
       " ('an', 'AT'),\n",
       " ('investigation', 'NN'),\n",
       " ('of', 'IN')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.tagged_words()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_lower = [[word for word in document.lower().split()] for document in courses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['writing',\n",
       " 'ii:',\n",
       " 'rhetorical',\n",
       " 'composing',\n",
       " 'rhetorical',\n",
       " 'composing',\n",
       " 'engages',\n",
       " 'you',\n",
       " 'in',\n",
       " 'a',\n",
       " 'series',\n",
       " 'of',\n",
       " 'interactive',\n",
       " 'reading,',\n",
       " 'research,',\n",
       " 'and',\n",
       " 'composing',\n",
       " 'activities',\n",
       " 'along',\n",
       " 'with',\n",
       " 'assignments',\n",
       " 'designed',\n",
       " 'to',\n",
       " 'help',\n",
       " 'you',\n",
       " 'become',\n",
       " 'more',\n",
       " 'effective',\n",
       " 'consumers',\n",
       " 'and',\n",
       " 'producers',\n",
       " 'of',\n",
       " 'alphabetic,',\n",
       " 'visual',\n",
       " 'and',\n",
       " 'multimodal',\n",
       " 'texts.',\n",
       " 'join',\n",
       " 'us',\n",
       " 'to',\n",
       " 'become',\n",
       " 'more',\n",
       " 'effective',\n",
       " 'writers...',\n",
       " 'and',\n",
       " 'better',\n",
       " 'citizens.',\n",
       " 'rhetorical',\n",
       " 'composing',\n",
       " 'is',\n",
       " 'a',\n",
       " 'course',\n",
       " 'where',\n",
       " 'writers',\n",
       " 'exchange',\n",
       " 'words,',\n",
       " 'ideas,',\n",
       " 'talents,',\n",
       " 'and',\n",
       " 'support.',\n",
       " 'you',\n",
       " 'will',\n",
       " 'be',\n",
       " 'introduced',\n",
       " 'to',\n",
       " 'a',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'rhetorical',\n",
       " 'concepts—that',\n",
       " 'is,',\n",
       " 'ideas',\n",
       " 'and',\n",
       " 'techniques',\n",
       " 'to',\n",
       " 'inform',\n",
       " 'and',\n",
       " 'persuade',\n",
       " 'audiences—that',\n",
       " 'will',\n",
       " 'help',\n",
       " 'you',\n",
       " 'become',\n",
       " 'a',\n",
       " 'more',\n",
       " 'effective',\n",
       " 'consumer',\n",
       " 'and',\n",
       " 'producer',\n",
       " 'of',\n",
       " 'written,',\n",
       " 'visual,',\n",
       " 'and',\n",
       " 'multimodal',\n",
       " 'texts.',\n",
       " 'the',\n",
       " 'class',\n",
       " 'includes',\n",
       " 'short',\n",
       " 'videos,',\n",
       " 'demonstrations,',\n",
       " 'and',\n",
       " 'activities.',\n",
       " 'we',\n",
       " 'envision',\n",
       " 'rhetorical',\n",
       " 'composing',\n",
       " 'as',\n",
       " 'a',\n",
       " 'learning',\n",
       " 'community',\n",
       " 'that',\n",
       " 'includes',\n",
       " 'both',\n",
       " 'those',\n",
       " 'enrolled',\n",
       " 'in',\n",
       " 'this',\n",
       " 'course',\n",
       " 'and',\n",
       " 'the',\n",
       " 'instructors.',\n",
       " 'we',\n",
       " 'bring',\n",
       " 'our',\n",
       " 'expertise',\n",
       " 'in',\n",
       " 'writing,',\n",
       " 'rhetoric',\n",
       " 'and',\n",
       " 'course',\n",
       " 'design,',\n",
       " 'and',\n",
       " 'we',\n",
       " 'have',\n",
       " 'designed',\n",
       " 'the',\n",
       " 'assignments',\n",
       " 'and',\n",
       " 'course',\n",
       " 'infrastructure',\n",
       " 'to',\n",
       " 'help',\n",
       " 'you',\n",
       " 'share',\n",
       " 'your',\n",
       " 'experiences',\n",
       " 'as',\n",
       " 'writers,',\n",
       " 'students,',\n",
       " 'and',\n",
       " 'professionals',\n",
       " 'with',\n",
       " 'each',\n",
       " 'other',\n",
       " 'and',\n",
       " 'with',\n",
       " 'us.',\n",
       " 'these',\n",
       " 'collaborations',\n",
       " 'are',\n",
       " 'facilitated',\n",
       " 'through',\n",
       " 'wex,',\n",
       " 'the',\n",
       " 'writers',\n",
       " 'exchange,',\n",
       " 'a',\n",
       " 'place',\n",
       " 'where',\n",
       " 'you',\n",
       " 'will',\n",
       " 'exchange',\n",
       " 'your',\n",
       " 'work',\n",
       " 'and',\n",
       " 'feedback']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_lower[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_tokenized = [[word.lower() for word in word_tokenize(document)] for document in courses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['writing',\n",
       " 'ii',\n",
       " ':',\n",
       " 'rhetorical',\n",
       " 'composing',\n",
       " 'rhetorical',\n",
       " 'composing',\n",
       " 'engages',\n",
       " 'you',\n",
       " 'in',\n",
       " 'a',\n",
       " 'series',\n",
       " 'of',\n",
       " 'interactive',\n",
       " 'reading',\n",
       " ',',\n",
       " 'research',\n",
       " ',',\n",
       " 'and',\n",
       " 'composing',\n",
       " 'activities',\n",
       " 'along',\n",
       " 'with',\n",
       " 'assignments',\n",
       " 'designed',\n",
       " 'to',\n",
       " 'help',\n",
       " 'you',\n",
       " 'become',\n",
       " 'more',\n",
       " 'effective',\n",
       " 'consumers',\n",
       " 'and',\n",
       " 'producers',\n",
       " 'of',\n",
       " 'alphabetic',\n",
       " ',',\n",
       " 'visual',\n",
       " 'and',\n",
       " 'multimodal',\n",
       " 'texts',\n",
       " '.',\n",
       " 'join',\n",
       " 'us',\n",
       " 'to',\n",
       " 'become',\n",
       " 'more',\n",
       " 'effective',\n",
       " 'writers',\n",
       " '...',\n",
       " 'and',\n",
       " 'better',\n",
       " 'citizens',\n",
       " '.',\n",
       " 'rhetorical',\n",
       " 'composing',\n",
       " 'is',\n",
       " 'a',\n",
       " 'course',\n",
       " 'where',\n",
       " 'writers',\n",
       " 'exchange',\n",
       " 'words',\n",
       " ',',\n",
       " 'ideas',\n",
       " ',',\n",
       " 'talents',\n",
       " ',',\n",
       " 'and',\n",
       " 'support',\n",
       " '.',\n",
       " 'you',\n",
       " 'will',\n",
       " 'be',\n",
       " 'introduced',\n",
       " 'to',\n",
       " 'a',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'rhetorical',\n",
       " 'concepts—that',\n",
       " 'is',\n",
       " ',',\n",
       " 'ideas',\n",
       " 'and',\n",
       " 'techniques',\n",
       " 'to',\n",
       " 'inform',\n",
       " 'and',\n",
       " 'persuade',\n",
       " 'audiences—that',\n",
       " 'will',\n",
       " 'help',\n",
       " 'you',\n",
       " 'become',\n",
       " 'a',\n",
       " 'more',\n",
       " 'effective',\n",
       " 'consumer',\n",
       " 'and',\n",
       " 'producer',\n",
       " 'of',\n",
       " 'written',\n",
       " ',',\n",
       " 'visual',\n",
       " ',',\n",
       " 'and',\n",
       " 'multimodal',\n",
       " 'texts',\n",
       " '.',\n",
       " 'the',\n",
       " 'class',\n",
       " 'includes',\n",
       " 'short',\n",
       " 'videos',\n",
       " ',',\n",
       " 'demonstrations',\n",
       " ',',\n",
       " 'and',\n",
       " 'activities',\n",
       " '.',\n",
       " 'we',\n",
       " 'envision',\n",
       " 'rhetorical',\n",
       " 'composing',\n",
       " 'as',\n",
       " 'a',\n",
       " 'learning',\n",
       " 'community',\n",
       " 'that',\n",
       " 'includes',\n",
       " 'both',\n",
       " 'those',\n",
       " 'enrolled',\n",
       " 'in',\n",
       " 'this',\n",
       " 'course',\n",
       " 'and',\n",
       " 'the',\n",
       " 'instructors',\n",
       " '.',\n",
       " 'we',\n",
       " 'bring',\n",
       " 'our',\n",
       " 'expertise',\n",
       " 'in',\n",
       " 'writing',\n",
       " ',',\n",
       " 'rhetoric',\n",
       " 'and',\n",
       " 'course',\n",
       " 'design',\n",
       " ',',\n",
       " 'and',\n",
       " 'we',\n",
       " 'have',\n",
       " 'designed',\n",
       " 'the',\n",
       " 'assignments',\n",
       " 'and',\n",
       " 'course',\n",
       " 'infrastructure',\n",
       " 'to',\n",
       " 'help',\n",
       " 'you',\n",
       " 'share',\n",
       " 'your',\n",
       " 'experiences',\n",
       " 'as',\n",
       " 'writers',\n",
       " ',',\n",
       " 'students',\n",
       " ',',\n",
       " 'and',\n",
       " 'professionals',\n",
       " 'with',\n",
       " 'each',\n",
       " 'other',\n",
       " 'and',\n",
       " 'with',\n",
       " 'us',\n",
       " '.',\n",
       " 'these',\n",
       " 'collaborations',\n",
       " 'are',\n",
       " 'facilitated',\n",
       " 'through',\n",
       " 'wex',\n",
       " ',',\n",
       " 'the',\n",
       " 'writers',\n",
       " 'exchange',\n",
       " ',',\n",
       " 'a',\n",
       " 'place',\n",
       " 'where',\n",
       " 'you',\n",
       " 'will',\n",
       " 'exchange',\n",
       " 'your',\n",
       " 'work',\n",
       " 'and',\n",
       " 'feedback']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_filtered_stopwords = [[word for word in document if not word in english_stopwords] for document in texts_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['writing',\n",
       " 'ii',\n",
       " ':',\n",
       " 'rhetorical',\n",
       " 'composing',\n",
       " 'rhetorical',\n",
       " 'composing',\n",
       " 'engages',\n",
       " 'series',\n",
       " 'interactive',\n",
       " 'reading',\n",
       " ',',\n",
       " 'research',\n",
       " ',',\n",
       " 'composing',\n",
       " 'activities',\n",
       " 'along',\n",
       " 'assignments',\n",
       " 'designed',\n",
       " 'help',\n",
       " 'become',\n",
       " 'effective',\n",
       " 'consumers',\n",
       " 'producers',\n",
       " 'alphabetic',\n",
       " ',',\n",
       " 'visual',\n",
       " 'multimodal',\n",
       " 'texts',\n",
       " '.',\n",
       " 'join',\n",
       " 'us',\n",
       " 'become',\n",
       " 'effective',\n",
       " 'writers',\n",
       " '...',\n",
       " 'better',\n",
       " 'citizens',\n",
       " '.',\n",
       " 'rhetorical',\n",
       " 'composing',\n",
       " 'course',\n",
       " 'writers',\n",
       " 'exchange',\n",
       " 'words',\n",
       " ',',\n",
       " 'ideas',\n",
       " ',',\n",
       " 'talents',\n",
       " ',',\n",
       " 'support',\n",
       " '.',\n",
       " 'introduced',\n",
       " 'variety',\n",
       " 'rhetorical',\n",
       " 'concepts—that',\n",
       " ',',\n",
       " 'ideas',\n",
       " 'techniques',\n",
       " 'inform',\n",
       " 'persuade',\n",
       " 'audiences—that',\n",
       " 'help',\n",
       " 'become',\n",
       " 'effective',\n",
       " 'consumer',\n",
       " 'producer',\n",
       " 'written',\n",
       " ',',\n",
       " 'visual',\n",
       " ',',\n",
       " 'multimodal',\n",
       " 'texts',\n",
       " '.',\n",
       " 'class',\n",
       " 'includes',\n",
       " 'short',\n",
       " 'videos',\n",
       " ',',\n",
       " 'demonstrations',\n",
       " ',',\n",
       " 'activities',\n",
       " '.',\n",
       " 'envision',\n",
       " 'rhetorical',\n",
       " 'composing',\n",
       " 'learning',\n",
       " 'community',\n",
       " 'includes',\n",
       " 'enrolled',\n",
       " 'course',\n",
       " 'instructors',\n",
       " '.',\n",
       " 'bring',\n",
       " 'expertise',\n",
       " 'writing',\n",
       " ',',\n",
       " 'rhetoric',\n",
       " 'course',\n",
       " 'design',\n",
       " ',',\n",
       " 'designed',\n",
       " 'assignments',\n",
       " 'course',\n",
       " 'infrastructure',\n",
       " 'help',\n",
       " 'share',\n",
       " 'experiences',\n",
       " 'writers',\n",
       " ',',\n",
       " 'students',\n",
       " ',',\n",
       " 'professionals',\n",
       " 'us',\n",
       " '.',\n",
       " 'collaborations',\n",
       " 'facilitated',\n",
       " 'wex',\n",
       " ',',\n",
       " 'writers',\n",
       " 'exchange',\n",
       " ',',\n",
       " 'place',\n",
       " 'exchange',\n",
       " 'work',\n",
       " 'feedback']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_filtered_stopwords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_punctuations = [',', '.', ':', ';', '?', '(', ')', '[', ']', '&', '!', '*', '@', '#', '$', '%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_filtered = [[word for word in document if not word in english_punctuations] for document in texts_filtered_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stem'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stem('stemmed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_stemmed = [[st.stem(word) for word in docment] for docment in texts_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['writ',\n",
       " 'ii',\n",
       " 'rhet',\n",
       " 'compos',\n",
       " 'rhet',\n",
       " 'compos',\n",
       " 'eng',\n",
       " 'sery',\n",
       " 'interact',\n",
       " 'read',\n",
       " 'research',\n",
       " 'compos',\n",
       " 'act',\n",
       " 'along',\n",
       " 'assign',\n",
       " 'design',\n",
       " 'help',\n",
       " 'becom',\n",
       " 'effect',\n",
       " 'consum',\n",
       " 'produc',\n",
       " 'alphabet',\n",
       " 'vis',\n",
       " 'multimod',\n",
       " 'text',\n",
       " 'join',\n",
       " 'us',\n",
       " 'becom',\n",
       " 'effect',\n",
       " 'writ',\n",
       " '...',\n",
       " 'bet',\n",
       " 'cit',\n",
       " 'rhet',\n",
       " 'compos',\n",
       " 'cours',\n",
       " 'writ',\n",
       " 'exchang',\n",
       " 'word',\n",
       " 'idea',\n",
       " 'tal',\n",
       " 'support',\n",
       " 'introduc',\n",
       " 'vary',\n",
       " 'rhet',\n",
       " 'concepts—that',\n",
       " 'idea',\n",
       " 'techn',\n",
       " 'inform',\n",
       " 'persuad',\n",
       " 'audiences—that',\n",
       " 'help',\n",
       " 'becom',\n",
       " 'effect',\n",
       " 'consum',\n",
       " 'produc',\n",
       " 'writ',\n",
       " 'vis',\n",
       " 'multimod',\n",
       " 'text',\n",
       " 'class',\n",
       " 'includ',\n",
       " 'short',\n",
       " 'video',\n",
       " 'demonst',\n",
       " 'act',\n",
       " 'envid',\n",
       " 'rhet',\n",
       " 'compos',\n",
       " 'learn',\n",
       " 'commun',\n",
       " 'includ',\n",
       " 'enrol',\n",
       " 'cours',\n",
       " 'instruct',\n",
       " 'bring',\n",
       " 'expert',\n",
       " 'writ',\n",
       " 'rhet',\n",
       " 'cours',\n",
       " 'design',\n",
       " 'design',\n",
       " 'assign',\n",
       " 'cours',\n",
       " 'infrastruct',\n",
       " 'help',\n",
       " 'shar',\n",
       " 'expery',\n",
       " 'writ',\n",
       " 'stud',\n",
       " 'profess',\n",
       " 'us',\n",
       " 'collab',\n",
       " 'facilit',\n",
       " 'wex',\n",
       " 'writ',\n",
       " 'exchang',\n",
       " 'plac',\n",
       " 'exchang',\n",
       " 'work',\n",
       " 'feedback']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_stemmed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stems = sum(texts_stemmed, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stems_once = set(stem for stem in set(all_stems) if all_stems.count(stem) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [[stem for stem in text if stem not in stems_once] for text in texts_stemmed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-27 10:56:11,094 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-02-27 10:56:11,169 : INFO : built Dictionary(2974 unique tokens: ['...', 'act', 'along', 'assign', 'becom']...) from 379 documents (total 47550 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-27 10:56:29,583 : INFO : collecting document frequencies\n",
      "2019-02-27 10:56:29,585 : INFO : PROGRESS: processing document #0\n",
      "2019-02-27 10:56:29,597 : INFO : calculating IDF weights for 379 documents and 2973 features (28933 matrix non-zeros)\n"
     ]
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-27 10:56:44,598 : INFO : using serial LSI version on this node\n",
      "2019-02-27 10:56:44,600 : INFO : updating model with new documents\n",
      "2019-02-27 10:56:44,829 : INFO : preparing a new chunk of documents\n",
      "2019-02-27 10:56:44,837 : INFO : using 100 extra samples and 2 power iterations\n",
      "2019-02-27 10:56:44,838 : INFO : 1st phase: constructing (2974, 110) action matrix\n",
      "2019-02-27 10:56:44,848 : INFO : orthonormalizing (2974, 110) action matrix\n",
      "2019-02-27 10:56:44,987 : INFO : 2nd phase: running dense svd on (110, 379) matrix\n",
      "2019-02-27 10:56:45,024 : INFO : computing the final decomposition\n",
      "2019-02-27 10:56:45,025 : INFO : keeping 10 factors (discarding 72.550% of energy spectrum)\n",
      "2019-02-27 10:56:45,030 : INFO : processed documents up to #379\n",
      "2019-02-27 10:56:45,033 : INFO : topic #0(3.823): 0.238*\"teach\" + 0.152*\"nbsp\" + 0.136*\"program\" + 0.118*\"learn\" + 0.115*\"mus\" + 0.106*\"heal\" + 0.103*\"comput\" + 0.098*\"stud\" + 0.098*\"network\" + 0.093*\"design\"\n",
      "2019-02-27 10:56:45,035 : INFO : topic #1(2.703): -0.611*\"de\" + -0.379*\"la\" + -0.217*\"en\" + -0.166*\"à\" + -0.162*\"los\" + -0.151*\"que\" + -0.149*\"cour\" + -0.145*\"un\" + -0.132*\"les\" + -0.120*\"curso\"\n",
      "2019-02-27 10:56:45,038 : INFO : topic #2(2.507): 0.619*\"teach\" + 0.207*\"portfolio\" + 0.191*\"assist\" + -0.150*\"mus\" + 0.133*\"improv\" + 0.118*\"undertak\" + 0.117*\"learn\" + 0.116*\"strongly\" + -0.113*\"network\" + 0.111*\"found\"\n",
      "2019-02-27 10:56:45,040 : INFO : topic #3(2.338): -0.807*\"mus\" + 0.172*\"heal\" + -0.170*\"sound\" + -0.098*\"art\" + -0.096*\"audio\" + -0.091*\"digit\" + 0.084*\"glob\" + 0.080*\"econom\" + -0.077*\"program\" + -0.073*\"writ\"\n",
      "2019-02-27 10:56:45,046 : INFO : topic #4(2.208): 0.358*\"heal\" + -0.291*\"program\" + 0.223*\"mus\" + -0.220*\"comput\" + -0.193*\"algorithm\" + -0.189*\"dat\" + -0.181*\"langu\" + 0.171*\"glob\" + -0.152*\"network\" + 0.121*\"food\"\n"
     ]
    }
   ],
   "source": [
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-27 10:58:47,684 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2019-02-27 10:58:47,713 : INFO : creating matrix with 379 documents and 10 features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Machine Learning'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(lsi[corpus])\n",
    "\n",
    "\n",
    "courses_name[210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_course = texts[210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_bow = dictionary.doc2bow(ml_course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_lsi = lsi[ml_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 8.619968394740985),\n",
       " (1, 0.7090697158225461),\n",
       " (2, 0.8187437405994136),\n",
       " (3, -0.27170835184066267),\n",
       " (4, -4.75588439038337),\n",
       " (5, 0.6572666787559578),\n",
       " (6, 1.9124406734024817),\n",
       " (7, 1.5845565701663726),\n",
       " (8, -0.16884545566875936),\n",
       " (9, 0.8928543183764652)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = index[ml_lsi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_sims = sorted(enumerate(sims), key=lambda item: -item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(210, 0.99999994),\n",
       " (174, 0.9746436),\n",
       " (63, 0.9618724),\n",
       " (141, 0.95175946),\n",
       " (189, 0.9497884),\n",
       " (238, 0.9466871),\n",
       " (184, 0.9396818),\n",
       " (220, 0.9358909),\n",
       " (74, 0.9309064),\n",
       " (219, 0.9304532)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_sims[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Probabilistic Graphical Models'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "courses_name[238]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
